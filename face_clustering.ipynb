{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7ltirPtytEN",
        "outputId": "3721845d-7d69-4abb-8fe1-1862d119a52a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 24 kB/s \n",
            "\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=1e33d97005dd8af0045aca897f53ead2b704f3e14ca44a7f7a11ef3fc94d72dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KxaKm9H5yXuN"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import face_recognition #detecting and recogniting faces\n",
        "import cv2 #intracting woth image\n",
        "import os # reading file name\n",
        "\n",
        "#image = face_recognition.load_image_file(\"two_hero.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch3pWknsz3x2",
        "outputId": "24448fdc-63bc-4b1f-d804-480f2314a8b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-05 06:25:12--  https://upload.wikimedia.org/wikipedia/commons/e/ed/Elon_Musk_Royal_Society.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.153.240, 2620:0:860:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.153.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 239507 (234K) [image/jpeg]\n",
            "Saving to: ‘known/elon.jpg’\n",
            "\n",
            "known/elon.jpg      100%[===================>] 233.89K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-05-05 06:25:12 (2.55 MB/s) - ‘known/elon.jpg’ saved [239507/239507]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir known\n",
        "\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/e/ed/Elon_Musk_Royal_Society.jpg -O known/elon.jpg\n",
        "#!wget C:\\Users\\user\\Desktop -O known/bill.jpg\n",
        "#!wget https://pmcvariety.files.wordpress.com/2017/05/mark-zuckerberg.jpg?w=681&h=383&crop=1 -O known/mark.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gBiDjPOAx56",
        "outputId": "16e15f8d-76e1-498d-e6b4-7ae27f64db0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘unknown’: File exists\n",
            "--2022-05-11 02:15:41--  https://upload.wikimedia.org/wikipedia/commons/a/a0/Bill_Gates_2018.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 318220 (311K) [image/jpeg]\n",
            "Saving to: ‘unknown/1.jpg’\n",
            "\n",
            "unknown/1.jpg       100%[===================>] 310.76K  1.03MB/s    in 0.3s    \n",
            "\n",
            "2022-05-11 02:15:42 (1.03 MB/s) - ‘unknown/1.jpg’ saved [318220/318220]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir unknown\n",
        "!wget  https://upload.wikimedia.org/wikipedia/commons/a/a0/Bill_Gates_2018.jpg -O unknown/1.jpg\n",
        "#!wget https://api.time.com/wp-content/uploads/2019/04/mark-zuckerberg-time-100-2019.jpg?quality=85&zoom=2 -O unknown/2.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f0pHmDsBpPE"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rOUtYdzGGxdR"
      },
      "outputs": [],
      "source": [
        "def read_img(path):\n",
        "  img = cv2.imread(path)  #read image\n",
        "  (h,w) = img.shape[:2] # fetch height and width\n",
        "  width = 500 # hard coding width\n",
        "  ratio = width / float(w)\n",
        "  height = int(h*ratio)\n",
        "  return cv2.resize(img,(width,height))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yAgaGgyluoc",
        "outputId": "076efe29-5c23-4d13-8466-aae9b72c6ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['elon']\n"
          ]
        }
      ],
      "source": [
        "known_encodings =[]\n",
        "known_names = []\n",
        "known_dir = 'known'\n",
        "for file in os.listdir(known_dir):\n",
        "  if '.jpg' in file:\n",
        "    img = read_img(known_dir + '/' + file)\n",
        "    img_enc = face_recognition.face_encodings(img)[0]\n",
        "\n",
        "    known_encodings.append(img_enc)\n",
        "    known_names.append(file.split('.')[0])\n",
        "print(known_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wTo-aFDCoivK"
      },
      "outputs": [],
      "source": [
        "unknown_dir = 'unknown'\n",
        "for file in os.listdir(unknown_dir):\n",
        "  if '.png' in file:\n",
        "    img = img_read(known_dir + '/' + file)\n",
        "    img_enc = face_recognition.face_encodings(img)[0]\n",
        "\n",
        "    results = face_recognition.compare_faces(known_encodings, img_enc)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8tnme3qQCbj"
      },
      "source": [
        "# ---경계선---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "ZHKtMuKzSVTi",
        "outputId": "8a0db172-2e3b-46de-cec1-7cc43174f8cd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import face_recognition\n",
        "import os # reading file name\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN #clustering에 필요 \n",
        "import re #문자열에서 숫자 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0iQEXPAR8QLp"
      },
      "outputs": [],
      "source": [
        "class Face():\n",
        "  def __init__(self, frame_id, name, box, encoding):\n",
        "    self.frame_id = frame_id\n",
        "    self.name = name\n",
        "    self.box = box\n",
        "    self.encoding = encoding\n",
        "\n",
        "class Face_clustering():\n",
        "  def __init__(self):\n",
        "    self.faces = []\n",
        "    self.capture_dir = \"captures\"\n",
        "    self.unique_cnt_dict = {}\n",
        "    self.person_class = 0\n",
        "  def capture_filename(self, frame_id):\n",
        "    return \"frame_{}.jpg\".format(frame_id)\n",
        "  def drawBox(self, frame, face):\n",
        "   (top, right, bottom, left) = face.box\n",
        "   #print(face.frame_id)\n",
        "   cv2.rectangle(frame, (left,top), (right,bottom), (0,0,255), 2)\n",
        "\n",
        "  def encode(self, src_file='./ironman.mp4', capture_per_sec = 1, stop=0): #frame 하나에서 얼굴 추출\n",
        "    video = cv2.VideoCapture(src_file) \n",
        "    if not video.isOpened():\n",
        "      print(\"video not opened\")\n",
        "      return\n",
        "    \n",
        "    print(video.get(cv2.CAP_PROP_FRAME_COUNT)) #총 프레임 수 \n",
        "    print(video.get(cv2.CAP_PROP_FPS)) # 초당 프레임 수\n",
        "    print(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    print(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    frame_per_sec = video.get(cv2.CAP_PROP_FPS)\n",
        "    total_frame = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "   # capture_per_sec = 1\n",
        "    frame_id=0\n",
        "    frame_between_capture = round(frame_per_sec / capture_per_sec) #30\n",
        "\n",
        "    if not os.path.exists(self.capture_dir): #/captures디렉토리가 없으면\n",
        "      os.mkdir(self.capture_dir)\n",
        "\n",
        "    while video.isOpened():\n",
        "      ret, frame = video.read()\n",
        "      frame_id+=1\n",
        "\n",
        "      if ret is True:\n",
        "        if frame_id % frame_between_capture == 0: \n",
        "          #cv2_imshow(frame)\n",
        "          \n",
        "          rgb_frame = frame[:,:,::-1] #BGR을 RGB 순으로 바꾸기\n",
        "          face_box = face_recognition.face_locations(rgb_frame, model=\"hog\")\n",
        "          face_encodings = face_recognition.face_encodings(rgb_frame, face_box)\n",
        "          # face_box.shape (top, right, bottom, left, face_개수)\n",
        "          #face_encodings.shape (128 vector, face_개수)\n",
        "          if not face_box:\n",
        "             # print(\"face_box 0: %d\" %frame_id)\n",
        "              continue\n",
        "\n",
        "          faces_in_frame = [] #feces_in_frame에 Face class 저장\n",
        "          for box, encodings in zip(face_box, face_encodings):\n",
        "            face = Face(frame_id, None, box, encodings)\n",
        "            faces_in_frame.append(face)\n",
        "            self.drawBox(frame, face)\n",
        "          \n",
        "\n",
        "          pathname = os.path.join(self.capture_dir, self.capture_filename(frame_id)) # captures/frame_#.jpg\n",
        "          cv2.imwrite(pathname, frame) # 해당 디렉토리에 이미지 저장\n",
        "\n",
        "          self.faces.extend(faces_in_frame) #extend는 iterable한것들을 append\n",
        "          #if cv2.waitKey(1) & 0xFF == ord('q'): # waitkey 안됨\n",
        "           # break\n",
        "      \n",
        "      else:\n",
        "        break\n",
        "    video.release()\n",
        "    return\n",
        "\n",
        "  def get_face_image(self, image, box):\n",
        "    (top, right, bottom, left) = box\n",
        "    image_height = image.shape[0]\n",
        "    image_width = image.shape[1]\n",
        "    box_width = right - left\n",
        "    box_height = bottom - top\n",
        "\n",
        "    top = max(top - box_height, 0)\n",
        "    bottom = min(bottom + box_height, image_height - 1)\n",
        "    left = max(left - box_width, 0)\n",
        "    right = min(right + box_width, image_width - 1)\n",
        "\n",
        "    return image[top:bottom, left:right]\n",
        "    #image (frame_height, frame_width, rgb)\n",
        "\n",
        "  def cluster(self):\n",
        "   # print(len(self.faces))\n",
        "    if len(self.faces) == 0:\n",
        "      return\n",
        "    encodings = [face.encoding for face in self.faces]\n",
        "\n",
        "    cm = DBSCAN(metric=\"euclidean\")\n",
        "    cm.fit(encodings)\n",
        "    # clustering 완료\n",
        "\n",
        "    label_ids, count = np.unique(cm.labels_, return_counts=True) #0부터 labeling, -1은 분류되지 않은 encoding\n",
        "    self.unique_cnt_dict = dict(zip(label_ids, count)) # 레이블당 프레임수\n",
        "    print(self.unique_cnt_dict)\n",
        "    self.person_class = len(label_ids) - 1 #사람 종류\n",
        "    for label_id in label_ids:\n",
        "      dir_name = \"ID%d\" % label_id\n",
        "     # if label_id > -1: # -1처리는 어떻게 해야하나\n",
        "      if not os.path.exists(dir_name): #/id# 디렉토리가 없으면\n",
        "        os.mkdir(dir_name)\n",
        "      index = np.where(cm.labels_ == label_id)[0]\n",
        "      #print(index)\n",
        "      for i in index:\n",
        "        #  print(f'faces : {self.faces}')\n",
        "        #  print(f'i : {i}')\n",
        "        #  print(f'type i : {type(i)}')\n",
        "          \n",
        "          frame_id = self.faces[i].frame_id\n",
        "          box = self.faces[i].box\n",
        "          pathname = os.path.join(self.capture_dir, self.capture_filename(frame_id)) # captures/frame_#.jpg\n",
        "          image = cv2.imread(pathname)\n",
        "          face_image = self.get_face_image(image, box)\n",
        "          filename = dir_name + '-' + self.capture_filename(frame_id) #ID1/frame_#.jpg\n",
        "          pathname = os.path.join(dir_name, filename)\n",
        "          cv2.imwrite(pathname, face_image)\n",
        "\n",
        "    print('clustering done')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Dol_VQgSUZqY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4597.0\n",
            "30.0\n",
            "1280.0\n",
            "544.0\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  import argparse\n",
        "\n",
        "  #ap = argparse.ArgumentParser()\n",
        "  #ap.add_argument(\"-e\", \"--encode\", help=\"video file top encode or '0' to encode web cam\")\n",
        "  #ap.add_argument(\"-c\", \"--capture\", default=1, type=int, help=\"# of frame to capture per second\")\n",
        "  #ap.add_argument(\"-s\", \"--stop\", default=0, type=int, help=\"stop encoding after # seconds\")\n",
        "  #args = ap.parse_args()\n",
        "\n",
        "  fc = Face_clustering()\n",
        " # if args.encode:\n",
        " #   src_file = args.encode\n",
        " #   if src_file == \"0\":\n",
        " #     src_file = 0\n",
        " #   fc.encode(src_file, args.capture, args.stop)\n",
        "  fc.encode()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SKgPeo-QUbKo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{-1: 5, 0: 6, 1: 12, 2: 25, 3: 6}\n",
            "clustering done\n"
          ]
        }
      ],
      "source": [
        " fc.cluster()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF46uUU9bHe7"
      },
      "outputs": [],
      "source": [
        "!rm -r captures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mwajxprgIri"
      },
      "outputs": [],
      "source": [
        "def image_to_video(self):\n",
        "  for i in range(self.person_class):\n",
        "    frame_id = []\n",
        "    dir_name = \"ID%d\" % i\n",
        "    for file in os.listdir(dir_name):\n",
        "      if '.jpg' in file:\n",
        "        id = int(re.sub(r'[^0-9]', '', file))\n",
        "        frame_id.append(id)\n",
        "        frame_id.sort()\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "face clustering",
      "provenance": []
    },
    "interpreter": {
      "hash": "44a77319976b772337bbde147318f0f026d2ef6bf2b590a85f5ffda024fbd60d"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('summarizer-ML')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
